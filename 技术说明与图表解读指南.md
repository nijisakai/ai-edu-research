# 技术说明与图表解读指南

## ——AI赋能基础教育研究项目完整技术文档

---

## 一、项目架构总览

### 1.1 系统架构

```
ai-edu-research/
├── data/                          # 原始数据
│   ├── all_papers.json           # 3815条工具/产品记录（主数据源）
│   └── 教育产品统计_V5.csv       # 教育产品分类辅助数据
│
├── src/                           # 分析代码（16个Python模块）
│   ├── core_analysis.py          # 模块1：基础描述性统计
│   ├── nlp_analysis.py           # 模块2：NLP文本挖掘（TF-IDF/LDA/聚类）
│   ├── advanced_stats.py         # 模块3：高级统计可视化（10张补充图）
│   ├── deep_clustering.py        # 模块4：深度聚类分析（8张聚类图）
│   ├── visualizations.py         # 模块5：基础可视化
│   ├── viz_part1.py / viz_part2.py # 模块5扩展：分批可视化
│   ├── premium_viz.py            # 模块6：高品质主图生成（fig_a/b/d系列）
│   ├── framework_viz.py          # 模块7：理论框架可视化（fig_e系列）
│   ├── insight_mining.py         # 模块8：深度洞察挖掘（fig_f系列）
│   ├── causal_analysis.py        # 模块9：因果分析与统计建模
│   ├── relabel_framework.py      # 辅助：框架标签重编码
│   ├── rebuild_all.py            # 构建引擎：MD→HTML→PDF
│   └── render_*.py               # PDF渲染辅助脚本
│
├── output/
│   ├── figures/                   # 97张可视化图（PNG/PDF格式，300DPI）
│   ├── paper/                     # 论文输出（MD/HTML/PDF）
│   ├── report/                    # 报告输出（MD/HTML/PDF）
│   └── *.json                     # 25个中间分析结果JSON文件
│
└── requirements.txt
```

### 1.2 数据流水线

```
原始数据 (JSON/CSV)
    │
    ▼
┌─────────────────────────────────────────┐
│  第一层：数据解析与清洗                    │
│  core_analysis.py                        │
│  · 读取3815条记录，去重得1690个案例        │
│  · 字段标准化（省份/学段/学科/场景）        │
│  · 输出：10个描述性统计JSON               │
└─────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────┐
│  第二层：NLP文本挖掘                      │
│  nlp_analysis.py                         │
│  · jieba分词 + 自定义词典（60+教育术语）    │
│  · TF-IDF关键词 / LDA主题 / KMeans聚类    │
│  · 技术路径模式提取 / 共现网络构建          │
│  · 输出：11个NLP分析JSON                  │
└─────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────┐
│  第三层：高级统计与因果分析                 │
│  advanced_stats.py + causal_analysis.py  │
│  + insight_mining.py                     │
│  · 对应分析/MCA / 卡方检验 / 回归分析      │
│  · 随机森林+SHAP / Theil指数分解           │
│  · Cramér's V关联矩阵 / 效应量计算         │
│  · 输出：统计分析JSON + fig_s/fig_f系列图   │
└─────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────┐
│  第四层：可视化生成                        │
│  premium_viz.py + framework_viz.py       │
│  + deep_clustering.py                    │
│  · 24张论文主图 (fig_a/b/c/d/e/f)         │
│  · 10张补充统计图 (fig_s)                  │
│  · 8张聚类分析图 (fig_c1-c8)              │
│  · 全部300DPI，中文标签                    │
└─────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────┐
│  第五层：文档构建                          │
│  rebuild_all.py                          │
│  · 解析论文/报告Markdown结构               │
│  · 基于文本标记(marker)定位插图位置         │
│  · Markdown→HTML（含CSS排版）              │
│  · Chrome Headless→PDF渲染                │
└─────────────────────────────────────────┘
```

### 1.3 核心依赖

| 库 | 用途 | 版本要求 |
|---|---|---|
| pandas | 数据处理 | ≥1.5 |
| numpy | 数值计算 | ≥1.24 |
| scikit-learn | ML算法（KMeans/TF-IDF/RandomForest/PCA） | ≥1.3 |
| scipy | 统计检验（chi2/mannwhitneyu/spearmanr） | ≥1.10 |
| matplotlib | 可视化基座 | ≥3.7 |
| seaborn | 统计可视化（heatmap/clustermap/violin） | ≥0.12 |
| jieba | 中文分词 | ≥0.42 |
| prince | 对应分析/MCA | ≥0.7 |
| umap-learn | UMAP降维（可选，PCA回退） | ≥0.5 |
| shap | SHAP特征解释 | ≥0.41 |
| markdown | Markdown→HTML转换 | ≥3.4 |

---

## 二、数据结构与预处理

### 2.1 原始数据结构

主数据文件 `all_papers.json` 包含3815条记录（每条对应一个"案例×工具"组合），每条记录约31个字段：

| 字段名 | 类型 | 示例 | 说明 |
|--------|------|------|------|
| 案例编号 | int | 172 | 唯一案例标识，去重后得1690个 |
| 省份 | str | "浙江省" | 30个省级行政区 |
| 学段 | str | "高中" | 小学/初中/高中/幼儿园/其他 |
| 学科 | str | "地理" | 50+学科分类 |
| 工具标准名 | str | "豆包" | 1830种独立工具 |
| 企业 | str | "字节跳动" | 1726家企业 |
| 主要应用场景 | str | "助学" | L1场景分类 |
| 次要应用场景 | str | "智能辅导系统" | L2场景分类 |
| 优势和创新点 | text | "通过AI实现..." | 教师自述创新描述（NLP核心语料） |
| 关键技术路径 | text | "数据采集→诊断→反馈" | 技术应用流程（路径分析语料） |
| 潜在成效 | text | "提升学习效率..." | 预期效果描述 |
| 培养方向 | str | "智育" | 五育分类 |
| is_自研 | bool | True/False | 是否教师自主研发 |

### 2.2 数据清洗逻辑

```python
# core_analysis.py 核心清洗逻辑

# 1. 读取原始数据
df = pd.read_json("data/all_papers.json")  # 3815条

# 2. 案例级去重（一个案例可能使用多个工具，产生多行记录）
cases = df.drop_duplicates(subset=['案例编号'])  # → 1690个唯一案例

# 3. 学段标准化
STAGE_MAP = {
    '小学': '小学', '初中': '初中', '高中': '高中',
    '幼儿园': '幼儿园', '学前': '幼儿园',
    # 其余归入"其他"
}
df['学段_main'] = df['学段'].map(lambda x: STAGE_MAP.get(x, '其他'))

# 4. 省份标准化（去除"省""市""自治区"等后缀用于部分分析）
df['省份_short'] = df['省份'].str.replace(r'(省|市|自治区|壮族|回族|维吾尔)', '', regex=True)
```

### 2.3 案例级 vs. 记录级分析

**关键区别**：3815条记录 vs. 1690个案例

- **记录级分析**（3815条）：用于工具使用频次统计、市场集中度、技术要素分布等——因为一个案例使用多个工具，每条工具记录都应计入
- **案例级分析**（1690个）：用于学段/学科/场景分布、聚类分析、创新深度评估等——避免多工具案例被重复计数

---

## 三、分析方法详解与核心代码

### 3.1 描述性统计（core_analysis.py）

**学段/学科/省份分布**：直接对案例或记录进行 `value_counts()` 频次统计。

**市场集中度计算**：
```python
# CR5/CR10计算
tool_counts = df['工具标准名'].value_counts()
total = tool_counts.sum()
cr5 = tool_counts.head(5).sum() / total * 100    # → 28.2%
cr10 = tool_counts.head(10).sum() / total * 100   # → 33.2%

# HHI指数（赫芬达尔-赫希曼指数）
shares = (tool_counts / total * 100)
hhi = (shares ** 2).sum()  # → 196.1（高度竞争市场，<1500）
```

### 3.2 NLP文本挖掘（nlp_analysis.py）

#### 3.2.1 中文分词与预处理

```python
import jieba

# 自定义词典（60+教育/AI专业术语，防止被错误切分）
CUSTOM_WORDS = [
    '人工智能', '大语言模型', '深度学习', '知识图谱', '自适应学习',
    '智慧教育', '精准教学', '学情分析', '智能批改', '核心素养',
    '翻转课堂', '项目式学习', '五育并举', '因材施教', ...
]
for word in CUSTOM_WORDS:
    jieba.add_word(word)

# 停用词表（490个无信息量的高频词）
STOPWORDS = set(['的', '了', '在', '是', '和', '与', '等', '对', ...])

def tokenize(text):
    words = jieba.lcut(text)
    return [w for w in words if len(w) >= 2 and w not in STOPWORDS]
```

#### 3.2.2 TF-IDF关键词提取

**原理**：TF-IDF（词频-逆文档频率）衡量一个词对特定文档的重要程度。TF高（在该文档中频繁出现）且IDF高（在整个语料库中罕见）的词，才是真正的"关键词"。

```python
import jieba.analyse

# 对每篇案例文本提取Top20关键词及权重
for text in innovation_texts:
    keywords = jieba.analyse.extract_tags(text, topK=20, withWeight=True)
    for word, weight in keywords:
        global_keywords[word] += weight

# 全局Top50关键词
top50 = global_keywords.most_common(50)
# 结果示例：[('智能推荐', 234.5), ('自适应学习', 189.2), ('数据分析', 156.8), ...]
```

#### 3.2.3 LDA主题建模

**原理**：LDA（Latent Dirichlet Allocation）假设每篇文档是多个"主题"的混合，每个"主题"是词汇上的概率分布。算法自动发现语料库中的潜在主题结构。

```python
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

# 1. 构建文档-词频矩阵
vectorizer = CountVectorizer(max_features=2000, max_df=0.85, min_df=3)
dtm = vectorizer.fit_transform(tokenized_texts)
# dtm形状：(1690案例, 2000个词)

# 2. 拟合LDA模型
lda = LatentDirichletAllocation(
    n_components=7,           # 主题数（经困惑度/一致性评估确定）
    random_state=42,
    max_iter=30,
    learning_method='online'  # 在线变分贝叶斯推断
)
lda.fit(dtm)

# 3. 获取每个主题的Top关键词
feature_names = vectorizer.get_feature_names_out()
for topic_idx, topic in enumerate(lda.components_):
    top_words = [feature_names[i] for i in topic.argsort()[:-16:-1]]
    # 例：Topic 0 = ['语文', '写作', '阅读', '课文', '生成', ...]

# 4. 获取每个文档的主题分布
doc_topics = lda.transform(dtm)
# doc_topics[i] = [0.05, 0.60, 0.10, ...]  文档i在各主题上的概率
```

**主题数选择**：通过困惑度（Perplexity，越低越好）和主题一致性（Coherence，越高越好）的综合评估，在K=5~12范围内确定K=7为最优。

#### 3.2.4 KMeans聚类分析

**原理**：KMeans将1690个案例基于TF-IDF特征向量划分为K个互不重叠的簇，使簇内案例相似、簇间案例差异最大。

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# 1. TF-IDF向量化（合并创新描述+技术路径+潜在成效）
combined_text = innovation + " " + tech_path + " " + potential_effect
vectorizer = TfidfVectorizer(max_features=1500, max_df=0.8, min_df=3)
tfidf_matrix = vectorizer.fit_transform(combined_texts)
# 矩阵形状：(1690, 1500)

# 2. 轮廓系数选K
for k in range(4, 16):
    km = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)
    labels = km.fit_predict(tfidf_matrix)
    score = silhouette_score(tfidf_matrix, labels, sample_size=1000)
    # 典型结果：K=10时silhouette≈0.42

# 3. 最终聚类
best_km = KMeans(n_clusters=10, random_state=42, n_init=10)
cluster_labels = best_km.fit_predict(tfidf_matrix)
```

**轮廓系数解读**：取值[-1, 1]，>0.5表示结构清晰，0.25-0.5表示结构合理，<0.25表示结构模糊。文本聚类通常在0.35-0.50之间。

#### 3.2.5 技术路径模式挖掘

```python
def parse_tech_path(text):
    """解析"A → B → C"格式的技术路径"""
    steps = re.split(r'\s*[→\->]+\s*', text)
    return [s.strip() for s in steps if s.strip()]

# 统计三种粒度
full_path_counter = Counter()    # 完整路径：如 "采集 → 诊断 → 反馈 → 改进"
step_counter = Counter()          # 单步频次：如 "诊断" 出现了多少次
transition_counter = Counter()    # 步骤转移：如 "采集→诊断" 出现了多少次

for text in tech_path_texts:
    path = parse_tech_path(text)
    full_path_counter[' → '.join(path)] += 1
    for step in path:
        step_counter[step] += 1
    for i in range(len(path) - 1):
        transition_counter[(path[i], path[i+1])] += 1
```

### 3.3 高级统计分析

#### 3.3.1 Cramér's V关联强度（fig_f02）

**原理**：Cramér's V是衡量两个类别变量关联强度的指标，取值[0,1]。基于卡方统计量标准化得到，不受样本量影响。

```python
from scipy import stats

def cramers_v(x, y):
    """计算两个类别变量之间的Cramér's V"""
    ct = pd.crosstab(x, y)
    chi2 = stats.chi2_contingency(ct)[0]
    n = ct.values.sum()
    r, k = ct.shape
    phi2 = chi2 / n
    denom = min(r, k) - 1
    return np.sqrt(phi2 / denom) if denom > 0 else 0

# 对14个特征两两计算V值，构建关联矩阵
features = ['自主研发', '使用大模型', '学段', '学科', 'iSTAR层级', '创新深度', ...]
corr_matrix = np.zeros((14, 14))
for i, j in combinations(range(14), 2):
    v = cramers_v(df[features[i]], df[features[j]])
    corr_matrix[i, j] = corr_matrix[j, i] = v
```

**效应量判据**：V < 0.1 弱关联，0.1-0.3 中等关联，> 0.3 强关联。

#### 3.3.2 随机森林 + SHAP分析（fig_f01）

**原理**：随机森林是集成学习方法，通过构建多棵决策树并投票得到预测结果。SHAP（SHapley Additive exPlanations）基于博弈论中的Shapley值，量化每个特征对单个预测结果的贡献。

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import shap

# 1. 准备特征矩阵
X = df[['自主研发', 'D1深度学习', 'D3循证教学', 'D4人机互信',
        'iSTAR层级', '技术代际', '工具数量', '省份经济tier']].values
y = df['创新深度等级'].values  # 1-5分

# 2. 训练随机森林
rf = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=42)
cv_scores = cross_val_score(rf, X, y, cv=5, scoring='accuracy')
# 5折交叉验证准确率 ≈ 66.3%

rf.fit(X, y)

# 3. Gini重要性（基于节点分裂的纯度增益）
gini_importance = rf.feature_importances_
# [0.221, 0.139, 0.078, ...]  自主研发 > D3循证 > iSTAR

# 4. SHAP值（基于Shapley值的模型无关解释）
explainer = shap.TreeExplainer(rf)
shap_values = explainer.shap_values(X)

# 5. 蜂群图（Beeswarm plot）
shap.summary_plot(shap_values, X, feature_names=feature_names)
```

#### 3.3.3 对应分析（Correspondence Analysis, fig_f03）

**原理**：对应分析是一种将列联表中行变量和列变量同时映射到低维空间的方法。它通过对列联表的标准化残差矩阵进行奇异值分解（SVD），使得关联强的类别在空间中靠近。

```python
import prince

# 1. 构建列联表
ct = pd.crosstab(df['学段_main'], df['学科'])

# 2. 拟合对应分析模型
ca = prince.CA(n_components=2)
ca = ca.fit(ct)

# 3. 获取行/列坐标
row_coords = ca.row_coordinates(ct)    # 学段在二维空间的坐标
col_coords = ca.column_coordinates(ct)  # 学科在二维空间的坐标

# 解释方差比例
inertia = ca.eigenvalues_ / ca.eigenvalues_.sum() * 100
# 例：[45.2%, 28.7%, ...]  前两个维度解释了73.9%的关联信息
```

#### 3.3.4 多重对应分析（MCA, fig_f04）

**原理**：MCA是对应分析的多变量推广。当需要同时分析3个以上类别变量的联合关系时使用。它将每个变量的每个水平（如"小学""自主研发""Gen4"）都映射为空间中的一个点。

```python
import prince

# 将多个类别变量编码为指示矩阵
mca_data = df[['学段', '自主研发状态', '技术代际', 'iSTAR层级', '创新深度等级']]

# 拟合MCA
mca = prince.MCA(n_components=2)
mca = mca.fit(mca_data)

# 获取各水平的坐标
col_coords = mca.column_coordinates(mca_data)
# 每个类别水平（如"小学""Gen4""HM2C"）都有一个(x, y)坐标
```

#### 3.3.5 Theil指数分解（fig_f05）

**原理**：Theil指数是衡量不平等程度的指标，其核心优势在于可分解性——可以将总不平等精确分解为"组间不平等"和"组内不平等"。

```python
import numpy as np

def theil_index(values):
    """计算Theil T指数"""
    n = len(values)
    mean_val = np.mean(values)
    if mean_val == 0:
        return 0
    ratios = values / mean_val
    ratios = ratios[ratios > 0]  # 去除零值
    return np.mean(ratios * np.log(ratios))

def theil_decomposition(df, group_col, value_col):
    """Theil指数分解：总 = 组间 + 组内"""
    total_theil = theil_index(df[value_col].values)

    groups = df.groupby(group_col)
    n_total = len(df)
    mean_total = df[value_col].mean()

    between = 0
    within = 0
    for name, group in groups:
        n_g = len(group)
        mean_g = group[value_col].mean()
        share = n_g / n_total

        # 组间部分
        if mean_g > 0 and mean_total > 0:
            between += share * (mean_g / mean_total) * np.log(mean_g / mean_total)

        # 组内部分
        within += share * (mean_g / mean_total) * theil_index(group[value_col].values)

    return {
        'total': total_theil,
        'between': between,          # 省间不平等
        'within': within,             # 省内不平等
        'between_share': between / total_theil * 100,  # → 1.9%
        'within_share': within / total_theil * 100,     # → 98.1%
    }
```

---

## 四、全部图表详解与解读指南

下面按照论文中的图号（图1-图24）逐一说明每张图的生成方法、数据来源和解读方式。

---

### 图1：1690个AI教育案例的省域分布热力图
**文件名**：`fig_a01_province_map.png` (447 KB)
**生成模块**：`premium_viz.py`
**数据来源**：按省份对1690个案例计数

**生成原理**：
基于中国地图底图，以颜色深浅编码各省案例数量。使用matplotlib的fill方法对各省多边形着色，颜色映射为连续色阶（浅→深 = 少→多）。

**解读方式**：
- **颜色越深 = 案例越多**。浙江省颜色最深（432例），是唯一的"深色"省份
- **空间格局**：整体呈"东密西疏"分布，东部沿海省份颜色显著深于西部内陆
- **第一梯队**：浙江（432）、四川（190）、重庆（166）、北京（135）
- **注意事项**：分布受活动推广力度影响，不能直接等同于各省AI教育应用的实际水平

---

### 图2：AI教育案例的学段分布（华夫饼图）
**文件名**：`fig_a02_stage_waffle.png` (407 KB)
**生成模块**：`premium_viz.py`

**生成原理**：
华夫饼图（Waffle Chart）是饼图的替代形式。将100个小方格排列成10×10的网格，每个方格代表约1%的案例。按学段占比为方格着色。

**解读方式**：
- **面积占比 = 案例占比**。小学（蓝色）占据超过一半的方格，是视觉上的绝对主体
- 初中（绿色）占约五分之一，幼儿园和高中各占约十分之一
- **核心信息**：小学是AI教育应用的绝对"主战场"（52.7%）
- **深层含义**：小学教师群体基数大、课程弹性高、评价压力低，为AI应用提供了更大空间

---

### 图3：各学科AI应用渗透率（棒棒糖图）
**文件名**：`fig_a03_subject_lollipop.png` (420 KB)
**生成模块**：`premium_viz.py`

**生成原理**：
棒棒糖图（Lollipop Chart）是条形图的变体，用一条线段+一个圆点替代矩形条。视觉更清爽，适合展示排序数据。圆点大小与数值成正比。

**解读方式**：
- **圆点越大/线段越长 = 该学科AI应用案例越多**
- 语文（577例）和数学（466例）两个圆点明显突出——因为LLM天然适配文本处理和逻辑推理
- **美术（235例）超过英语（208例）**——这是AI图像生成工具（如即梦AI）对美术教学的颠覆性影响
- 体育（127例）和心理健康教育（40例）的出现说明AI正在向非认知领域渗透

---

### 图4：四类应用场景的案例体量对比（树图）
**文件名**：`fig_a04_scenario_treemap.png` (516 KB)
**生成模块**：`premium_viz.py`

**生成原理**：
树图（Treemap）将数值映射为矩形面积——面积越大代表数值越大。采用squarify算法将总空间递归分割为大小成比例的矩形。

**解读方式**：
- **面积 = 案例占比**。"助学"占据约四分之三的面积，视觉冲击力极强
- "助教"仅占一隅（17.5%），"助育"和"助评"几乎不可辨识
- **核心信息**：AI教育应用高度集中于"辅助学生学习"这一单一场景
- **政策含义**：AI在教学评价（3.0%）和学校管理（2.1%）领域的潜力远未释放

---

### 图5：五育维度的案例数量与人机协同深度（雷达图）
**文件名**：`fig_a05_five_edu_radar.png` (1.4 MB)
**生成模块**：`premium_viz.py`

**生成原理**：
双轴雷达图在同一张图中叠加两组数据——案例数量（实线）和人机协同深度/HM2C占比（虚线），共享五个顶点（智育/德育/美育/体育/劳育）。

**解读方式**：
- **两条线的形状差异是关键**：
  - 实线（数量）：智育一枝独大，其余四育缩成一团
  - 虚线（深度）：智育优势大幅缩小，美育和体育的深度反而接近甚至超过智育
- **反直觉发现**：规模优势 ≠ 质量优势。非智育领域虽然体量小，但人机协同更深（美育HM2C=51.0%，体育=52.2%，智育=41.1%）
- **解释**：非智育领域天然要求更高的创造性整合，倒逼教师超越"工具替代"的浅层应用

---

### 图6：AI教育工具使用频次Top20（水平条形图）
**文件名**：`fig_b01_top20_tools.png` (460 KB)
**生成模块**：`premium_viz.py`

**生成原理**：
按工具在3815条记录中的出现频次降序排列，取Top20绘制水平条形图。

**解读方式**：
- 豆包（387次）和DeepSeek（289次）远远领先，两者合计占比近18%
- 其后各工具条形急剧缩短，形成**"陡坡式"衰减曲线**
- 前三名（豆包/DeepSeek/即梦AI）均为国产生成式AI产品
- **核心信息**：大语言模型已成为AI教育应用的"基础设施"，教师倾向选择通用工具而非教育专用产品

---

### 图7：技术要素-应用场景-教学环节的多级流转路径（桑基图）
**文件名**：`fig_b02_tech_sankey.png` (386 KB)
**生成模块**：`premium_viz.py`

**生成原理**：
桑基图（Sankey Diagram）以流的宽度编码流量大小。从左到右展示"技术要素→应用场景→教学环节"的三级流转。每条流的宽度与对应的案例/记录数成正比。

**解读方式**：
- **左侧**：NLP和数据分析是最粗的两个源节点
- **中间**：大部分流量汇入"助学"这一条主干流
- **右侧**：分散到课堂教学、课后巩固等教学环节
- **核心信息**：少数主干路径承载了绝大部分技术应用流量，呈现高度集中化

---

### 图8：AI教育大模型产品的市场定位与覆盖面（景观图）
**文件名**：`fig_b03_model_landscape.png` (831 KB)
**生成模块**：`premium_viz.py`

**解读方式**：
- 横轴=产品的通用性-垂直性定位，纵轴=教育场景的覆盖广度，气泡大小=使用频次
- 豆包和DeepSeek的气泡最大，位于"高通用性、宽覆盖"象限
- 希沃白板等教育专用产品气泡小但位于"高垂直性"象限
- **核心信息**：当前市场呈"通用底座 vs. 垂直应用"的二分格局

---

### 图9：AI工具共现关系网络图
**文件名**：`fig_b04_cooccurrence_network.png` (1.7 MB)
**生成模块**：`premium_viz.py`

**生成原理**：
基于NLP共现分析构建网络图。节点=AI工具，节点大小∝使用频次；边=两个工具在同一案例中被共同使用，边粗细∝共现次数。使用力导向布局算法（spring layout）确定节点位置。

**解读方式**：
- **"核心-边缘"结构**：豆包、DeepSeek等大节点居于中心，与多种工具形成密集连线
- 大量小节点分布在外围，仅有稀疏连线
- **核心信息**：市场同时存在"头部集中"和"尾部碎片化"两种特征

---

### 图10：1690个案例的UMAP降维聚类可视化
**文件名**：`fig_c01_umap_clusters.png` (917 KB)
**生成模块**：`deep_clustering.py`

**生成原理**：
UMAP（Uniform Manifold Approximation and Projection）是一种非线性降维算法，将1500维的TF-IDF特征空间映射到2维平面，同时尽可能保持数据点之间的局部邻域关系。不同颜色标记10个KMeans聚类。

```python
import umap
reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)
embedding = reducer.fit_transform(tfidf_matrix.toarray())
```

**解读方式**：
- 每个点=一个案例，颜色=聚类标签
- **团簇的紧凑度**反映聚类内部的同质性（如"大模型辅助语文"类团簇紧凑）
- **团簇间距离**反映应用模式的差异性（如"编程教育"与"语文写作"团簇远离）
- **重叠区域**表示模式边界模糊的案例（如跨学科项目类团簇较松散）

---

### 图11：AI教育工具市场集中度洛伦兹曲线
**文件名**：`fig_d01_lorenz_curve.png` (637 KB)
**生成模块**：`premium_viz.py`

**生成原理**：
洛伦兹曲线是经济学中衡量分配不均的经典工具。横轴=工具的累计百分比（从使用最少到最多排列），纵轴=累计市场份额。对角线代表完全均等分配。

```python
sorted_vals = np.sort(tool_counts.values)
cumvals = np.cumsum(sorted_vals)
lorenz_x = np.arange(1, n+1) / n        # 累计工具百分比
lorenz_y = cumvals / cumvals[-1]         # 累计市场份额
gini = 1 - 2 * np.trapz(lorenz_y, lorenz_x)
```

**解读方式**：
- **曲线离对角线越远=分配越不均**。本图曲线极度弯曲
- 约80%的工具仅贡献了不到20%的市场份额
- 前3%的工具贡献了超过50%的份额
- **Gini系数**越接近1越不平等（本图中约为0.85-0.90）

---

### 图12：EdTech产品生态的层次结构（嵌套树图）
**文件名**：`fig_d02_ecosystem_treemap.png` (530 KB)
**生成模块**：`premium_viz.py`

**解读方式**：
- 外层按产品形态分组（软件平台、硬件+AI等），内层按企业填充
- **字节跳动生态**（豆包+即梦AI+剪映AI）在软件平台区域占据最大面积
- 背景中1726家企业形成碎片化的马赛克
- **核心信息**：字节跳动生态占16.6%市场份额，形成平台依赖风险

---

### 图13：AI教育创新深度的地理不平等Theil指数分解
**文件名**：`fig_f05_geographic_inequality.png` (649 KB)
**生成模块**：`insight_mining.py`

**解读方式**：
- **上层条形图**：各省创新深度均分
- **下层堆叠面积图**：省间与省内不平等的贡献比例
- **关键数字**：省内不平等占98.1%，省间仅1.9%
- **核心发现**：AI教育的"数字鸿沟"主要不是省际差距，而是同一省份内部的微观差距
- **政策含义**：缩小差距的关键不在区域间资源转移，而在省内经验扩散

---

### 图14：三赋能框架与iSTAR人机协同层级映射
**文件名**：`fig_e01_sanfuneng_istar.png` (412 KB)
**生成模块**：`framework_viz.py`

**解读方式**：
- 以矩阵形式交叉呈现"三赋能"（赋能学生/教师/学校）与iSTAR层级（Level 0-3）
- 颜色深浅=该交叉单元格的案例密度
- **"赋能学生×Level 1"**单元格颜色最深——绝大多数案例集中于此
- **"赋能学校×Level 2-3"**区域几乎空白
- **核心信息**：AI教育应用的结构性失衡——过度集中于"助学+初级协同"

---

### 图15：智慧教育三重境界的递进关系与当前阶段定位
**文件名**：`fig_e03_three_realms.png`
**生成模块**：`framework_viz.py`

**解读方式**：
- 三级台阶呈现智慧教育的递进境界
- 第一境界"智慧学习环境"标注"当前主体"
- 一二境界之间标注"过渡区"（少数先行案例）
- 第三境界标注"远景目标"
- **核心信息**：当前AI教育实践整体处于第一境界向第二境界过渡阶段

---

### 图16：数字教学法四维框架达成度诊断（雷达图）
**文件名**：`fig_e04_digital_pedagogy_radar.png` (1.1 MB)
**生成模块**：`framework_viz.py`

**解读方式**：
- 四个维度：技术赋能深度学习、绿色鲁棒环境、循证导向、人机互信
- **"循证导向"轴延伸最长**——数据驱动教学已有进展
- **"深度学习"和"人机互信"轴明显较短**——发展滞后
- 不对称的四边形轮廓=结构性失衡
- **核心信息**：数据采集能力领先，但深度学习促进和人机互信建设严重不足

---

### 图17：10个聚类的创新深度评分分布（岭线图）
**文件名**：`fig_e02_innovation_ridgeline.png` (718 KB)
**生成模块**：`framework_viz.py`

**生成原理**：
岭线图（Ridgeline Plot）将多个密度分布曲线垂直层叠，每条"山脊"代表一个聚类的创新深度分布。使用核密度估计（KDE）平滑。

**解读方式**：
- 每条山脊的**峰值位置**反映该聚类的典型创新深度
- 山脊**偏右**=创新深度较高，**偏左**=较低
- 山脊**宽度**=内部离散程度
- **核心信息**：不同应用模式的创新深度差异显著，"先行者"与"跟随者"之间存在明显的创新鸿沟

---

### 图18：技术代际与应用场景的交叉分布（气泡图）
**文件名**：`fig_e05_techgen_scenario_bubble.png` (643 KB)
**生成模块**：`framework_viz.py`

**解读方式**：
- 横轴=技术代际（Gen1-Gen5），纵轴=应用场景（助学/助教/助育/助评/助管）
- 气泡大小=案例数量，颜色=创新深度均分
- Gen4（大模型）行的气泡集中在"助学"列且颜色偏暖（创新深度高）
- **反直觉发现**：Gen1-2行个别气泡颜色也较深——"低技术高创新"现象

---

### 图19：随机森林模型SHAP特征重要性（蜂群图）
**文件名**：`fig_f01_rf_shap.png` (498 KB)
**生成模块**：`insight_mining.py`

**如何阅读SHAP蜂群图**：
每个点代表一个案例。横轴是SHAP值（正值=推高创新深度预测，负值=拉低）。颜色编码特征值的高低（红色=高值，蓝色=低值）。特征按总体影响力从上到下排列。

**解读方式**：
- **自主研发状态**排在最上方，正向SHAP值分布最宽，红色点集中在正向区域——自研是创新深度最强的预测因子
- D3循证教学和iSTAR层级紧随其后
- 学段、区域等结构性特征的SHAP值接近零——几乎无预测力
- **核心信息**：过程能力（教学设计、人机协同）压倒结构因素（地区、学段）

---

### 图20：关键变量间Cramér's V关联强度（热力图）
**文件名**：`fig_f02_cramers_v.png` (850 KB)
**生成模块**：`insight_mining.py`

**解读方式**：
- 颜色越深=两个变量之间的关联越强
- **自主研发×创新深度**色块最深（V值最高）
- **学段×创新深度**色块较浅
- **核心信息**：教学设计能力（而非结构性因素）决定创新深度

---

### 图21：学段-学科-场景对应分析（双标图）
**文件名**：`fig_f03_correspondence_biplot.png` (876 KB)
**生成模块**：`insight_mining.py`

**如何阅读对应分析双标图**：
对应分析将行变量（学段）和列变量（学科/场景）同时映射到二维空间。**空间距离反映关联强度**——越近的变量在数据中越倾向于共同出现。**原点代表"平均"模式**，远离原点的变量代表偏离主流的差异化模式。

**解读方式**：
- **靠近原点**的变量（小学、助学、语文）= 主流模式
- **远离原点**的变量（幼儿园-环境创设、高中-助研）= 差异化模式
- 如果"高中"和"物理"靠近=高中案例中物理学科占比高于平均水平
- 坐标轴解释的方差比例标注在轴标签中

---

### 图22：多维特征联合关系的多重对应分析（MCA双标图）
**文件名**：`fig_f04_mca_biplot.png` (609 KB)
**生成模块**：`insight_mining.py`

**如何阅读MCA双标图**：
MCA将多个类别变量的所有水平同时投影到二维空间。每个点代表一个类别水平（如"自研""Gen4""HM2C"等）。**空间位置靠近=在数据中倾向于共同出现**。

**解读方式**：
- **"高创新集群"**（自研、Gen4+、HM2C）聚集在一个象限
- **"低创新集群"**（第三方工具、Gen1-2、HMC(1)）聚集在对角象限
- 两个集群的**空间分离**直观揭示了创新差异背后的多维特征组合
- **核心信息**：高创新案例具有"自主研发+新一代AI+深度人机协同"的三重特征

---

### 图23：聚类方差分析效应量对比（柱状图）
**文件名**：`fig_f06_cluster_anova.png` (586 KB)
**生成模块**：`insight_mining.py`

**生成原理**：
对10个KMeans聚类在各连续维度上进行单因素ANOVA（方差分析），计算eta-squared效应量——即该维度的变异中有多少比例可由聚类归属解释。

```python
from scipy import stats

for dim in ['D1深度学习', 'D3循证教学', 'D4人机互信', '创新深度']:
    groups = [df[df['cluster']==c][dim].values for c in range(10)]
    F, p = stats.f_oneway(*groups)

    # eta-squared = SS_between / SS_total
    ss_total = sum((df[dim] - df[dim].mean())**2)
    ss_between = sum(len(g) * (g.mean() - df[dim].mean())**2 for g in groups)
    eta_sq = ss_between / ss_total
```

**解读方式**：
- D4人机互信的柱子最高（eta²=0.989）——该维度对聚类区分贡献最大
- D3循证教学次之（eta²=0.778）
- **核心信息**：10种应用模式的核心差异在于人机协同深度，而非学段或学科

---

### 图24：研究核心数据指标综合仪表板
**文件名**：`fig_e06_dashboard.png` (1.0 MB)
**生成模块**：`framework_viz.py`

**解读方式**：
- 多面板布局，整合全研究的核心指标
- 包含：样本规模、学段分布、五育结构、工具Top10、市场集中度、区域热力图等
- **用途**：一站式数据总览，适合作为报告首页或汇报PPT

---

## 五、文档构建引擎

### 5.1 rebuild_all.py 工作原理

```
Markdown文件
    │
    ▼
┌──────────────────┐
│  结构解析          │  regex提取标题/摘要/关键词/正文/参考文献
│  parse_*_structure │
└──────────────────┘
    │
    ▼
┌──────────────────┐
│  Markdown→HTML    │  python-markdown库 + tables/footnotes/toc扩展
│  md_to_html()     │
└──────────────────┘
    │
    ▼
┌──────────────────┐
│  后处理           │  三线表class / blockquote→table容器 / 图注样式
│  post_process_*   │
└──────────────────┘
    │
    ▼
┌──────────────────┐
│  图片插入          │  基于文本标记(marker)定位插入点
│  insert_*_figures  │  在</p>标签后插入<div class="figure-block">
└──────────────────┘
    │
    ▼
┌──────────────────┐
│  模板填充          │  论文模板(宋体/三线表/学术风)
│  HTML_TEMPLATE     │  报告模板(深青色/金色/咨询风)
└──────────────────┘
    │
    ▼
┌──────────────────┐
│  PDF渲染          │  Chrome Headless --print-to-pdf
│  render_pdf()     │  (WeasyPrint因pango兼容问题已弃用)
└──────────────────┘
```

### 5.2 图片插入机制

图片插入的核心逻辑是**基于文本标记（marker）定位**：

```python
# 定义插入规则：(标记文本, 图片键名)
insertions = [
    ("浙江省以432个案例位居首位", "fig1"),   # 找到这段文字后，在其所在</p>标签后插入图1
    ("幼儿园阶段的AI应用占比达到11.2%", "fig2"),
    ...
]

for marker, fig_key in insertions:
    pos = html.find(marker)              # 在HTML中搜索标记文本
    if pos >= 0:
        end_p = html.find("</p>", pos)   # 找到该段落的结束标签
        insert_pos = end_p + 4            # 在</p>后面插入
        html = html[:insert_pos] + fig_html + html[insert_pos:]
```

**设计思路**：不在Markdown中硬编码图片路径，而是在HTML渲染后动态插入。这样Markdown保持纯文本可读性，图片位置可以灵活调整。

### 5.3 运行方式

```bash
# 完整重建（HTML + PDF）
cd /Users/sakai/Desktop/产业调研/ai-edu-research
python3 src/rebuild_all.py

# 仅查看输出
open output/paper/论文_AI赋能基础教育的实践图景与产业生态.html
open output/report/研究报告_AI赋能基础教育实践图景与产业生态分析.html
```

---

## 六、补充统计图（fig_s系列）简要说明

| 图号 | 文件名 | 方法 | 核心发现 |
|------|--------|------|----------|
| S1 | fig_s1_correspondence_analysis.png | 对应分析 | 学段×学科关联结构 |
| S2 | fig_s2_chi_square_mosaic.png | 卡方检验+马赛克图 | 学段×场景的显著关联 |
| S3 | fig_s3_correlation_matrix.png | Cramér's V矩阵+层次聚类 | 14个二值特征的关联网络 |
| S4 | fig_s4_tool_diversity_regression.png | 线性回归 | 案例数↔工具多样性的正相关 |
| S5 | fig_s5_tech_adoption_curve.png | Rogers创新扩散曲线 | Gen4+工具已达50%拐点 |
| S6 | fig_s6_subject_scenario_alluvial.png | 冲积图 | 学科→场景→五育的三级流转 |
| S7 | fig_s7_innovation_depth_boxplot.png | 小提琴图+Mann-Whitney U | 各学段创新深度分布比较 |
| S8 | fig_s8_geographic_inequality.png | 洛伦兹曲线+Gini系数 | 省域案例分布的不平等程度 |
| S9 | fig_s9_effect_size_forest.png | 效应量森林图+Bootstrap CI | 各特征对学段差异的贡献排序 |
| S10 | fig_s10_interaction_heatmap.png | 四面板交互热力图 | 不同学段中场景×五育的组合模式 |

---

## 七、深度聚类图（fig_c系列）简要说明

| 图号 | 文件名 | 方法 | 核心内容 |
|------|--------|------|----------|
| C1 | fig_c1_tsne_clusters.png | t-SNE降维+凸包 | 聚类的二维可视化（备选UMAP） |
| C2 | fig_c2_cluster_profiles.png | 六维雷达图×10个聚类 | 各聚类的特征画像 |
| C3 | fig_c3_dendrogram.png | Ward层次聚类树状图 | 聚类的层次关系 |
| C4 | fig_c4_silhouette.png | 轮廓系数分析 | 聚类质量评估（含K选择曲线） |
| C5 | fig_c5_cluster_heatmap.png | TF-IDF热力图+层次聚类 | 各聚类的关键词特征 |
| C6 | fig_c6_cluster_composition.png | 四面板堆叠条形图 | 各聚类的学段/学科/场景/五育构成 |
| C7 | fig_c7_umap_3d.png | UMAP三维投影（第三维→点大小） | 三维结构的二维展示 |
| C8 | fig_c8_cluster_evolution.png | 技术路径桑基图 | 各聚类的主导技术路径 |

---

*本文档详细说明了项目的完整技术架构、分析方法、核心代码和全部图表的解读方式，供研究团队参考。*
